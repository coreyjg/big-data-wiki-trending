# big-data-wiki-trending

Real-time Trending Wikipedia Topics Pipeline using Kafka, Spark Structured Streaming, Cassandra & Docker

---

## ğŸš€ Quickstart

1. **Clone the repo**  
   ```bash
   git clone https://github.com/coreyjg/big-data-wiki-trending.git
   cd big-data-wiki-trending
   ```

2. **Bring up the infrastructure**  
   ```bash
   cd infra
   docker compose up -d
   ```

3. **Start the producer** (in a new shell)  
   ```bash
   cd producer
   source .venv/bin/activate  # activate the Python virtual environment
   ./wiki_producer.py
   ```

---

## ğŸ“‚ Repo structure

- `infra/` â€“ Docker Compose configs for Kafka, Zookeeper, and Cassandra  
- `producer/` â€“ Python app that streams Wikimedia â€œrecentchangeâ€ events into Kafka  
- `processing/` â€“ *Coming soon*: Spark Structured Streaming job  
- `dashboard/` â€“ *Coming soon*: Visualization layer (Grafana or React)  
- `docs/` â€“ Architecture diagrams, design notes, and documentation

---

## ğŸ› ï¸ Prerequisites

- Docker & Docker Desktop (with WSL2 integration on Windows)  
- Python 3.8+  
- (Optional) VS Code with the Remote â€“ WSL extension for editing under WSL

---

## ğŸ” Next Steps

- Scaffold and run the Spark Structured Streaming job in `processing/`  
- Build the dashboard in `dashboard/`
